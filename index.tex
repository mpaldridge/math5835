% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{remark}
\AtBeginDocument{\renewcommand*{\proofname}{Proof}}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\newtheorem{refremark}{Remark}[chapter]
\newtheorem{refsolution}{Solution}[chapter]
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={MATH5835M Statistical Computing},
  pdfauthor={Matthew Aldridge},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{MATH5835M Statistical Computing}
\author{Matthew Aldridge}
\date{2027-06-09}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\chapter*{Schedule}\label{schedule}
\addcontentsline{toc}{chapter}{Schedule}

\markboth{Schedule}{Schedule}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2
\end{verbatim}

\bookmarksetup{startatroot}

\chapter*{About MATH5835}\label{about-math5835}
\addcontentsline{toc}{chapter}{About MATH5835}

\markboth{About MATH5835}{About MATH5835}

\bookmarksetup{startatroot}

\chapter{Introduction to Statistical
Computing}\label{introduction-to-statistical-computing}

\section{What is statistical
computing?}\label{what-is-statistical-computing}

\section{Probability and statistics
background}\label{probability-and-statistics-background}

\section{R programming}\label{r-programming}

\part{Monte Carlo estimation}

\chapter{Introduction to Monte Carlo}\label{introduction-to-monte-carlo}

Today, we'll start the first main topic of the module, which is called
``Monte Carlo estimation''.
\[\newcommand{\Exg}{\operatorname{\mathbb{E}}} \]
\[ \newcommand{\Ex}{\mathbb{E}} \]

\section{What is Monte Carlo
estimation?}\label{what-is-monte-carlo-estimation}

Let \(X\) be a random variable. We recall the \textbf{expectation}
\(\Ex X\) of \(X\): if \(X\) is discrete with probability mass function
(PMF) \(p\), then this is \[ \Ex X = \sum_x x\,p(x) ;\] while if \(X\)
is continuous with probability density function (PDF) \(f\), then this
is \[ \Ex X = \int_{-\infty}^{+\infty} x\,f(x)\,\mathrm{d}x . \] More
generally, the expectation of a function \(\phi\) of \(X\) is
\[ \Exg \phi(X) = \begin{cases} {\displaystyle \sum_x \phi(x)\,p(x)} & \text{for $X$ discrete}\\ {\displaystyle \int_{-\infty}^{+\infty} \phi(x)\,f(x)\,\mathrm{d}x}  & \text{for $X$ continuous.} \end{cases}\]
(This matches with the ``plain'' expectation when \(\phi(x) = x\).)

But how do we actually \emph{calculate} an expectation like one of
these? If \(X\) is discrete and can only take a small, finite number of
values, we can simply do the sum \(\sum_x \phi(x)\,p(x)\). Otherwise, we
just have to hope that \(\phi\) and \(p\) or \(f\) are sufficiently
``nice'' that we can manage to work out the sum/integral using a pencil
and paper. But while this is often the case in the sort of ``toy
example'' one comes across in maths or statistics lectures, this is very
rare in ``real life''.

\textbf{Monte Carlo estimation} is the idea that we can get an
approximate answer for \(\Ex X\) or \(\Exg \phi(X)\) if we have access
to lots of samples from \(X\). For example, if we have access to
\(X_1, X_2 \dots, X_n\) , independent and identically distributed
(\textbf{IID}) samples with the same distribution as \(X\), then we
already know that the mean
\[ \overline X = \frac{1}{n}(X_1 + X_2 + \cdots + X_n) = \frac{1}{n} \sum_{i=1}^n X_i \]
is usually close to the expectation \(\Ex X\), at least if \(n\) is big.
Similarly, it should be the case that
\[ \frac{1}{n} \big(\phi(X_1) + \phi(X_2) + \cdots + \phi(X_n) \big) = \frac{1}{n} \sum_{i=1}^n \phi(X_i) \]
should be close to \(\Exg \phi(X)\).

In this course we will write that \(X_1, X_2, \dots, X_n\) is a
``\textbf{random sample} from \(X\)'' to mean that
\(X_1, X_2, \dots, X_n\) are IID with the same distribution as \(X\).

\begin{definition}[]\protect\hypertarget{def-MCest}{}\label{def-MCest}

Let \(X\) be a random variable, \(\phi\) a function, and write
\(\theta = \Exg\phi(X)\). Suppose that \(X_1, X_2, \dots, X_n\) are a
random sample from \(X\). Then the \textbf{Monte Carlo estimate}
\(\widehat\theta_n^{\mathrm{MC}}\) is
\[ \widehat{\theta}_n^{\mathrm{MC}} = \frac{1}{n} \sum_{i=1}^n \phi(X_i) . \]

\end{definition}

While general ideas for estimating using simulation go back a long time,
the modern theory of Monte Carlo estimation was developed by the
physicists \href{https://en.wikipedia.org/wiki/Stanisław_Ulam}{Stanislaw
Ulam} and \href{John\%20von\%20Neumann}{John von Neumann}. Ulam (who was
Polish) and von Neumann (who was Hungarian) moved to the US in the early
1940s to work on the Manhattan project to build the atomic bomb (as made
famous by the film Oppenheimer). Later in the 1940s, they worked
together in the Los Alamos National Laboratory continuing their research
on nuclear weapons, where they used simulations on early computers to
help them numerically solve difficult mathematical and physical
problems. The name ``Monte Carlo'' was chosen because the use of
randomness to solve such problems reminded them of gamblers in the
casinos of Monte Carlo, Monaco. Ulam and von Neumann also worked closely
with another colleague Nicholas Metropolis, whose work we will study
later in this module.

\section{Examples}\label{examples}

Let's see some simple examples of Monte Carlo esimation using R.

\begin{example}[]\protect\hypertarget{exm-MCexp}{}\label{exm-MCexp}

Let's suppose we've forgotten the expectation of the exponential
distribution \(X \sim \operatorname{Exp}(2)\) with rate 2. In this
simple case, we could work out the answer using the PMF
\(f(x) = 2\mathrm{e}^{2x}\) as
\[ \Ex X = \int_0^\infty x\,2\mathrm{e}^{2x}\,\mathrm{d}x \] (and,
without too much difficulty, get the answer \(\frac12\)). But instead,
let's do this the Monte Carlo way.

In R, we can use the \texttt{rexp()} function to get IID samples from
the exponential distribution: the full syntax is
\texttt{rexp(n,\ rate)}, which gives \texttt{n} samples from an
exponential distribution with rate with rate \texttt{rate}. So our code
here should be

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{samples }\OtherTok{\textless{}{-}} \FunctionTok{rexp}\NormalTok{(n, }\DecValTok{2}\NormalTok{)}
\NormalTok{MCest }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ n) }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(samples)}
\NormalTok{MCest}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.4494966
\end{verbatim}

So our Monte Carlo estimate is 0.44950, to 5 decimal places.

To get a (probably) more accurate estimation, we could use more samples.
We could also simplify the fourth line of this code by using the
\texttt{mean()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FloatTok{1e6}
\NormalTok{samples }\OtherTok{\textless{}{-}} \FunctionTok{rexp}\NormalTok{(n, }\DecValTok{2}\NormalTok{)}
\NormalTok{MCest }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(samples)}
\NormalTok{MCest}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5001086
\end{verbatim}

(In the second line, \texttt{1e6} is R code for the scientific notation
\(1 \times 10^6\), or a million.)

Our new Monte Carlo estimate is 0.50011, which is closer to the true
value of 2.

\end{example}

\begin{example}[]\protect\hypertarget{exm-MC2}{}\label{exm-MC2}

Let's try another example. Let \(X \sim \operatorname{N}(1, 2^2)\) be a
normal distribution with mean 0 and standard deviation 2. Suppose we
want to find out \(\Exg(\sin X)\) (for some reason). While it
\emph{might} be possible to somehow calculate the integral
\[ \Exg(\sin X) = \int_{-\infty}^{+\infty} (\sin x) \, \frac{1}{\sqrt{2\pi\times 2^2}} \exp\left(\frac{(x - 1)^2}{2\times 2^2}\right) \, \mathrm{d} x , \]
that looks extremely difficult to me.

Instead, a Monte Carlo estimation of \(\Exg(\sin X)\) is very
straightforwards

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FloatTok{1e6}
\NormalTok{samples }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{MCest }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{sin}\NormalTok{(samples))}
\NormalTok{MCest}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1156834
\end{verbatim}

Our Monte Carlo estimate is 0.11568.

\end{example}

\section{Random samples in R}\label{random-samples-in-r}

In this lecture, we've got random samples from distributions using
\texttt{rexp()} (exponential distribution) and \texttt{rnorm} (normal).

Generally, R has built in functions for generating random samples for
the most common distributions. These include:

\begin{itemize}
\item
  \texttt{rbinom(n,\ size,\ prob)} for \texttt{n} samples from the
  binomial distribution
  \(\operatorname{Bin}(\mathtt{size}, \texttt{prob})\). Includes
  \texttt{rbinom(n,\ 1,\ prob)} for the Bernoulli distribution
  \(\operatorname{Bern}(\mathtt{prob})\).
\item
  \texttt{rgeom(n,\ prob)} for \texttt{n} samples from the geometric
  distribution \(\operatorname{Geom}(\mathtt{prob})\). (Note that R uses
  the ``number of failures \emph{before} for the first success''
  definition of the geometric, starting from 0.)
\item
  \texttt{rpois(n,\ \textbackslash{}lambda)} for \texttt{n} samples from
  the Poisson distribution \(\operatorname{Po}(\mathtt{lambda})\).
\item
  \texttt{rexp(n,\ rate)} for \texttt{n} samples from the exponential
  distribution \(\operatorname{Exp}(\mathtt{rate})\). If the
  \texttt{rate} parameter is omitted, then \texttt{rate\ =\ 1} is
  assumed by default.
\item
  \texttt{rnorm(n,\ mean,\ sd)} for \texttt{n} samples from the normal
  distribution \(\operatorname{N}(\mathtt{mean},\mathtt{sd}^2)\). Note
  that the third argument is the standard deviation \(\sigma\), not the
  variance \(\sigma^2\). If the \texttt{mean} and \texttt{sd} parameters
  are omitted, then \texttt{mean\ =\ 0} and \texttt{sd\ =\ 1} are
  assumed by default.
\item
  \texttt{runif(n,\ min,\ max)} for \texttt{n} samples from the
  continuous uniform distribution on the interval
  \([\mathtt{min}, \mathtt{max}]\). If the \texttt{min} and \texttt{max}
  parameters are omitted, the interval \([0,1]\) is assumed by default.
  (This will turn out to be the most important sampling distribution in
  this module.)
\item
  Look at the help file \texttt{?distributions} in R for details of
  other distributions.
\end{itemize}

Also, we can sample from a discrete random variable on a finite number
of outcomes with

\begin{verbatim}
sample(x, n, replace = TRUE, prob = p)
\end{verbatim}

Here, \texttt{x} is a vector of values the random variable can take,
\texttt{n} is the number of samples, and \texttt{p} is a vector of
probabilities of each value of \texttt{x} (in the same order). If
\texttt{prob\ =\ p} is omitted, equal uniform probabilities of each
outcome are assumed by default.

In Part II of this module, we will look at how R manages to sample from
these distributions. Then we will be able to do it ourselves ``from
scratch'', and also be able to sample from distributions that R doesn't
have built-in functions for.

\chapter{Monte Carlo examples}\label{monte-carlo-examples}

\section{Example of Monte Carlo
estimation}\label{example-of-monte-carlo-estimation}

\section{Monte Carlo estimation of
probabilities}\label{monte-carlo-estimation-of-probabilities}

\section{Monte Carlo estimation of
integrals}\label{monte-carlo-estimation-of-integrals}

\chapter{Monte Carlo error}\label{monte-carlo-error}

\section{Reminder: bias and error}\label{reminder-bias-and-error}

\section{Reminder: limit theorems}\label{reminder-limit-theorems}

\section{Bias and error of the Monte Carlo
estimator}\label{bias-and-error-of-the-monte-carlo-estimator}

\chapter{Control variates}\label{control-variates}

\chapter{Antithetic variables I}\label{antithetic-variables-i}

\section{Estimation with correlation}\label{estimation-with-correlation}

\section{Estimation with antithetic
variables}\label{estimation-with-antithetic-variables}

\section{Estimating π again}\label{estimating-ux3c0-again}

\chapter*{Problem Sheet 1}\label{problem-sheet-1}
\addcontentsline{toc}{chapter}{Problem Sheet 1}

\markboth{Problem Sheet 1}{Problem Sheet 1}

Basic MC example

Basic MC with error estimation

Pi

Control variate example

Pi with antithetic

\chapter{Antithetic variables II}\label{antithetic-variables-ii}

\section{Error with antithetic
variables}\label{error-with-antithetic-variables}

\section{Antithetic variables:
example}\label{antithetic-variables-example}

\section{Finding antithetic
variables}\label{finding-antithetic-variables}

\chapter{Importance sampling I}\label{importance-sampling-i}

\section{Variance reduction}\label{variance-reduction}

\section{Rejection}\label{rejection}

\section{Importance sampling:
definition}\label{importance-sampling-definition}

\chapter{Importance sampling II}\label{importance-sampling-ii}

\section{Error of importance
sampling}\label{error-of-importance-sampling}

\section{Importance sampling:
example}\label{importance-sampling-example}

\section{Picking a good distribution}\label{picking-a-good-distribution}

\part{Random number generation}

\chapter{Generating random numbers}\label{generating-random-numbers}

\chapter{LCGs}\label{lcgs}

\chapter*{Problem Sheet 2}\label{problem-sheet-2}
\addcontentsline{toc}{chapter}{Problem Sheet 2}

\markboth{Problem Sheet 2}{Problem Sheet 2}

\chapter{Uniform and discrete
generation}\label{uniform-and-discrete-generation}

\chapter{Inverse transform method}\label{inverse-transform-method}

\chapter{Rejection sampling}\label{rejection-sampling}

\chapter{Envelope rejection sampling
I}\label{envelope-rejection-sampling-i}

\chapter{Envelope rejection sampling
II}\label{envelope-rejection-sampling-ii}

\chapter*{Problem Sheet 3}\label{problem-sheet-3}
\addcontentsline{toc}{chapter}{Problem Sheet 3}

\markboth{Problem Sheet 3}{Problem Sheet 3}

\part{MCMC}

\chapter{Introduction to Markov
chains}\label{introduction-to-markov-chains}

\chapter{Long-run behaviour of Markov
chains}\label{long-run-behaviour-of-markov-chains}

\chapter{Markov chains in continuous
space}\label{markov-chains-in-continuous-space}

\chapter{Metropolis--Hastings algorithm
I}\label{metropolishastings-algorithm-i}

\chapter{Metropolis--Hastings algorithm
I}\label{metropolishastings-algorithm-i-1}

\chapter{Convergence and mixing}\label{convergence-and-mixing}

\chapter{MCMC and Bayesian
statistics}\label{mcmc-and-bayesian-statistics}

\chapter*{Problem Sheet 4}\label{problem-sheet-4}
\addcontentsline{toc}{chapter}{Problem Sheet 4}

\markboth{Problem Sheet 4}{Problem Sheet 4}

\part{Bootstrap}

\chapter{Empirical distribution}\label{empirical-distribution}

\chapter{Bootstrap estimation}\label{bootstrap-estimation}

\chapter{Bootstrap error}\label{bootstrap-error}

\chapter{Bootstrap confidence
intervals}\label{bootstrap-confidence-intervals}

\chapter*{Problem Sheet 5}\label{problem-sheet-5}
\addcontentsline{toc}{chapter}{Problem Sheet 5}

\markboth{Problem Sheet 5}{Problem Sheet 5}

\bookmarksetup{startatroot}

\chapter{FAQ}\label{faq}

\bookmarksetup{startatroot}

\chapter{Coursework}\label{coursework}



\end{document}
