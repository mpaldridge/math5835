# Monte Carlo error II: practice

{{< include ../_header.qmd >}}

## Recap

Let's recap where we've got to. We know that the Monte Carlo estimate for $\theta = \Exg \phi(X)$ is 
$$ \widehat{\theta}_n^{\mathrm{MC}} = \frac{1}{n} \sum_{i=1}^n \phi(X_i) .$$
Last time, we saw that the Monte Carlo estimator is unbiased, and that its mean-square and root-mean-square errors are
$$ \operatorname{MSE}\big(\widehat{\theta}_n^{\mathrm{MC}}\big) = \frac{1}{n} \operatorname{Var}\big(\phi(X)\big) \qquad \operatorname{RMSE}\big(\widehat{\theta}_n^{\mathrm{MC}}\big) = \sqrt{\frac{1}{n} \operatorname{Var}\big(\phi(X)\big)} . $$
We saw that these themselves can be estimated as $S^2/n$ and $S/\sqrt{n}$ respectively, where $S^2$ is the sample variance of the $\phi(X_i)$s.

Let's do one more example before moving on.

::: {#exm-MCprob2}
In @exm-MCprob, we were estimating $\mathbb P(Z > 2)$, where $Z$ is a standard normal.

Our code was

```{r}
n <- 1e6
samples <- rnorm(n, 0, 1)
MCest <- mean(samples > 2)
MCest
```

So our root-mean-square error can be approximated as

```{r}
RMSEest <- sqrt(var(samples > 2) / n)
RMSEest
```
:::

## Confidence intervals

So far, we have described our error tolerance in terms of the MSE or RMSE. But we could have talked about "confidence intervals" or "margins of error" instead. This might be easier to understand for non-mathematicians, for whom "root-mean-square error" doesn't really mean anything.

Here, we will want to appeal to the central limit theorem approximation. A bit more probability revision: Let $Y_1, Y_2, \dots$ be IID again, with expectation $\mu$ and variance $\sigma^2$. Write $\overline Y_n$ for the mean. We've already reminded ourselves that $\mathbb E \overline Y_n = \mu$  and $\Var(\overline{Y}_n) = \sigma^2/n$. But the **central limit theorem** says that the distribution of $\overline Y_n$ is approximately normally distributed with those parameters, so $\overline Y_n \approx \operatorname{N}(\mu, \sigma^2/n)$ when $n$ is large. (This is an informal statement of the central limit theorem: you probably know some more formal ways to more precisely state the it, but this will do for us.)

Recall that, in the normal distribution $\operatorname{N}(\mu, \sigma^2)$, we expect to be within $1.96$ standard deviations of the mean with 95% probability. More generally, the interval $[\mu - q_{1-\alpha/2}\sigma, \mu + q_{1-\alpha/2}\sigma]$, where $q_{1-\alpha/2}$ is the $(1- \frac{\alpha}{2})$-quantile of the normal distribution, contains the true value with probability approximately $1 - \alpha$.

We can form an approximate confidence interval for a Monte Carlo estimate using this idea. We have our Monte Carlo estimate $\widehat{\theta}_n^\mathrm{MC}$ as our estimate of the expectation, and our estimate of the root-mean-square error $S/\sqrt{n}$ as our estimate of the variance. So our confidence interval is estimated as 
$$\bigg[ \widehat{\theta}_n^\mathrm{MC} - q_{1-\alpha/2}\,\frac{S}{\sqrt{n}}, \ \widehat{\theta}_n^\mathrm{MC} + q_{1-\alpha/2}\,\frac{S}{\sqrt{n}} \bigg] . $$

::: {#exm-MCprob3}
We continue the example of @exm-MCprob and @exm-MCprob2, where we were estimating $\mathbb P(Z > 2)$ for $Z$ a standard normal. 


```{r}
n <- 1e6
samples <- rnorm(n, 0, 1)
MCest   <- mean(samples > 2)
RMSEest <- sqrt(var(samples > 2) / n)
```

Our confidence interval is estimates as follows

```{r}
alpha <- 0.05
quant <- qnorm(1 - alpha / 2)
c(MCest - quant * RMSEest, MCest + quant * RMSEest)
```
:::

## How many samples do I need?

In our examples we've picked the number of samples $n$ for our estimator, then approximated the error based on that. But we could do things the other way around -- fix an error tolerance that we're willing to deal with, then work out what sample size we need to achieve it.

We know that the root-mean-square error is
$$ \operatorname{RMSE}\big(\widehat{\theta}_n^{\mathrm{MC}}\big) = \sqrt{\frac{1}{n} \operatorname{Var}\big(\phi(X)\big)} $$
So if we want to get the RMSE down to $\epsilon$, say, then this shows that we need
$$ n = \frac{1}{\epsilon^2} \Var\big(\phi(X)\big) . $$

We can make use of this idea with a three-step process:

1. Run an initial "pilot" Monte Carlo algorithm with a small number of samples $n$. Use the results of the "pilot" to estimate the variance $S^2 \approx \Var(\phi(X))$. We want $n$ small enough that this runs very quickly, but big enough that we get a reasonably OK estimate of the variance.

1.  Pick a desired RMSE accuracy $\epsilon$. We now know that we require roughly $N = S^2 / \epsilon^2$ samples to get our desired accuracy.

1. Run the "real" Monte Carlo algorithm with this big number of samples $N$. We will put up with this being quite slow, because we know we're definitely going to get the error tolerance we need.

::: {#exm-MC22}
Let's try this with @exm-MC2 from before. We were trying to esimate $\Exg(\sin X)$, where $X \sim \operatorname{N}(1, 2^2)$.

We'll start with just $n = 1000$ samples, for our pilot study

```{r,}
n_pilot <- 1000
samples <- rnorm(n_pilot, 1, 2)
var_est <- var(sin(samples))
var_est
```
  
This was super-quick! We won't have got a super-accurate estimate of $\Exg\phi(X)$, but we have a reasonable idea what $\Var(\phi(X))$. This will allow us to pick out "real" sample size in order to get a root-mean-square error of $10^{-4}$.

```{r,}
epsilon <- 1e-4
n_real  <- round(var_est / epsilon^2)
n_real
```

We need about 50 million samples! This is a lot, but now we know we're going to get the accuracy we want, so it's worth it. (Here, 50 million samples will only take a few second on a modern computer, but this is the sort of code that one could leave running overnight, for example.)

```{r}
samples <- rnorm(n_real, 1, 2)
MCest <- mean(sin(samples))
MCest
RMSEest <- sqrt(var(sin(samples)) / n_real)
RMSEest
```

This was very slow! But we see that we have indeed got our Monte Carlo estimate to (near enough) the desired accuracy.
:::

We should note that the equation
$$ n = \frac{1}{\epsilon^2} \Var\big(\phi(X)\big) $$
is actually quite bad news. To get an RMSE of $\epsilon$ we need order $1/\epsilon^2$ samples. That's not good. Think of it like this: to *double* the accuracy we need to *quadruple* the number of samples. Even worse: to get "one more decimal place of accuracy" means dividing $\epsilon$ by ten; but that means multiplying the number of samples by one hundred!

Wouldn't it be nice to have some better ways of increasing the accuracy of a Monte Carlo estimate besides just taking more and more samples?

**Next time:** *We begin our study of clever "variance reduction" methods for Monte Carlo estimation.* 

::: {.mysummary}
**Summary:**

* We can approximate confidence intervals for a Monte Carlo estimate by using a normal approximation.

* To get the mean-square error below $\epsilon$ we need $n = \Var(\phi(X))/\epsilon^2$ samples.

**Read more:** [Voss, *An Introduction to Statistical Computing*](https://leeds.primo.exlibrisgroup.com/permalink/44LEE_INST/1fj430b/cdi_askewsholts_vlebooks_9781118728031), Subsections 3.2.2--3.2.4.
:::