# Monte Carlo error

::: {.hidden}
$$\newcommand{\Exg}{\operatorname{\mathbb{E}}} 
\newcommand{\Ex}{\mathbb{E}} 
\newcommand{\Ind}{\mathbb{I}}$$
:::

## Bias and error of the Monte Carlo estimator

In this lecture, we're going to be looking more carefully at the size of the errors made by the Monte Carlo estimate
$$ \widehat{\theta}_n^{\mathrm{MC}} = \frac{1}{n} \big(\phi(X_1) + \phi(X_2) + \cdots + \phi(X_n) \big) = \frac{1}{n} \sum_{i=1}^n \phi(X_i) . $$

In doing so, we'll be making particular use of the probability and statistics background that we talked about back in [....]

Our main result is the following.

::: {#thm-MCerr}
Let $X$ be a random variable, $\phi$ a function, and $\theta = \Exg\phi(X)$. Let
$$ \widehat{\theta}_n^{\mathrm{MC}} = \frac{1}{n} \big(\phi(X_1) + \phi(X_2) + \cdots + \phi(X_n) \big) = \frac{1}{n} \sum_{i=1}^n \phi(X_i) $$
be the Monte Carlo estimate of $\theta$. Then:

1. $\widehat{\theta}_n^{\mathrm{MC}}$ is unbiased, in that $\operatorname{bias}\big(\widehat{\theta}_n^{\mathrm{MC}}\big) = 0$.

1. The variance of of $\widehat{\theta}_n^{\mathrm{MC}}$ is 
${\displaystyle \operatorname{Var}\big(\widehat{\theta}_n^{\mathrm{MC}}\big) = \frac{1}{n} \operatorname{Var}\big(\phi(X)\big)}$.

1. The mean-square error of $\widehat{\theta}_n^{\mathrm{MC}}$ is 
${\displaystyle \operatorname{MSE}\big(\widehat{\theta}_n^{\mathrm{MC}}\big) = \frac{1}{n} \operatorname{Var}\big(\phi(X)\big)}$.

1. The root-mean-square error of $\widehat{\theta}_n^{\mathrm{MC}}$ is 
${\displaystyle \operatorname{RMSE}\big(\widehat{\theta}_n^{\mathrm{MC}}\big) = \frac{1}{\sqrt{n}} \operatorname{sd}\big(\phi(X)\big)}$.
:::

::: {.proof}
Apply the probability facts from [.....], with $Y = \phi(X)$. This gives:

1. $\Ex \widehat{\theta}_n^{\mathrm{MC}} = \Ex Y = \Exg \phi(X)$, so $\operatorname{bias}(\widehat{\theta}_n^{\mathrm{MC}}) = \Exg \phi(X) - \Exg \phi(X) = 0$

1. ${\displaystyle \operatorname{Var}(\widehat{\theta}_n^{\mathrm{MC}}) = \frac{1}{n} \operatorname{Var}(Y) = \frac{1}{n} \operatorname{Var}\big(\phi(X)\big)}$

1. Using @thm-MSE-bias,
$$\operatorname{MSE}(\widehat{\theta}_n^{\mathrm{MC}}) = \operatorname{bias}(\widehat{\theta}_n^{\mathrm{MC}})^2 + \operatorname{Var}(\widehat{\theta}_n^{\mathrm{MC}}) = 0^2 + \frac{1}{n} \operatorname{Var}\big(\phi(X)\big) = \frac{1}{n} \operatorname{Var}\big(\phi(X)\big) . $$

1. Take the square root of part 3.
:::

There's a problem here, though. The reason we are doing Monte Carlo estimation in the first place is that we *couldn't* calculate $\Exg \phi(X)$. So it seems very unlikely we'll be able to calculate the variance $\operatorname{Var}(\phi(X))$ either. But we *can* estimate the variance from our samples too: by taking the sample variance of our samples $\phi(x_i)$.


## Examples

That's enough theory. Let's see some examples.

::: {#exm-MCexp2}
Let's go back to the very first example in the module, @exm-MCexp, where we were trying to find the expectation of an $\operatorname{Exp}(2)$ random variable. We used this R code:

```{r, cache = TRUE}
n <- 1e6
samples <- rexp(n, 2)
MCest <- mean(samples)
MCest
```

(Because Monte Carlo estimation is random, this won't be the *exact* same estimate we had before, of course.)

So if we want to investigate the error, we can use the sample variance of these samples.

```{r, cache = TRUE}
var_est <- var(samples)
MSEest  <- var_est / n
RMSEest <- sqrt(MSEest)
c(var_est, MSEest, RMSEest)
```

The first number is `var_est` $= `r signif(var_est, 3)`$, the sample variance of our $\phi(x_i)$s:
$$ s^2 = \frac{1}{n-1} \sum_{i=1}^n \big(\phi(x_i) - \widehat{\theta}_n^{\mathrm{MC}}\big)^2 . $$
This should be a good estimate of the true variance $\operatorname{Var}(\phi(X))$.

The second number is `MSEest` $= `r signif(var_est/n, 3)`$, our estimate of the mean-square error. Since $\operatorname{MSE}(\widehat{\theta}_n^{\mathrm{MC}}) = \frac{1}{n} \operatorname{Var}(\phi(X))$, our estimate of the MSE is $\frac{1}{n} s^2$.

The third number is `RMSEest` $= `r signif(sqrt(var_est/n), 3)`$ our estimate of the root-mean square error, which is simply the square-root of our estimate of the mean-square error.
:::

::: {#exm-MCprob2}
In @exm-MCprob, we were estimating $\mathbb P(Z > 2)$, where $Z$ is a standard normal.

Our code was
```{r}
n <- 1e6
samples <- rnorm(n, 0, 1)
MCest <- mean(samples > 2)
MCest
```
So our root-mean-square error can be approximated as
```{r}
RMSEest <- sqrt(var(samples > 2) / n)
RMSEest
```
:::

## How many samples do I need?

In our examples we've picked the number of samples $n$ for our estimator, then approximated the error based on that. But we could do things the other way around -- fix an error tolerance that we're willing to deal with, then choose the sample size based on that.

That is, we have a three-step process:

1. Run an initial "pilot" Monte Carlo algorithm with a small number of samples $n$. We want $n$ small enough that this runs very quickly.

1. Approximate the error. Then use this to decide what value $n$ we will need for the "real" Monte Carlo algorithm.

1. Run the "real" Monte Carlo algorithm with this big number of samples $n$. We will put up with this being quite slow, because we know we're definitely going to get the error tolerance we need.

::: {#exm-MC22}
Let's try this with @exm-MC2 from before. We were trying to esimate $\Exg(\sin X)$, where $X \sim \operatorname{N}(1, 2^2)$.

We'll start with just $n = 1000$ samples, for our pilot study

```{r, cache = TRUE}
n_pilot <- 1000
samples <- rnorm(n_pilot, 1, 2)
var_est <- var(sin(samples))
var_est
```
  
This was super-quick! But with only 1000 samples, it won't have been an accurate estimate yet.

Let's suppose we want to get the root-mean-square error down to $\epsilon = 10^{-4}$. We know, using `var_est` to estimate the variance, that we want
$$ \epsilon = \operatorname{RMSE} \big(\widehat{\theta}_n^{\mathrm{MC}}\big) = \frac{1}{\sqrt{n}} \,\operatorname{sd}\big(\phi(X)\big) \approx \frac{1}{\sqrt{n}} \times \sqrt{`r signif(var_est, 4)`} . $$
Rearranging to make $n$ the subject and using $\epsilon = 10^{-4}$, we need
$$ n \approx `r signif(var_est, 4)`\times \frac{1}{\epsilon^2} = `r signif(var_est, 3)`\times 10^{8} =  `r signif(var_est * 1e8, 4)` \approx `r signif(var_est * 1e8, 1)`$$
samples, or about 50 million.

```{r, cache = TRUE}
epsilon <- 1e-4
n_real  <- round(var_est / epsilon^2)
n_real
samples <- rnorm(n_real, 1, 2)
MCest <- mean(sin(samples))
MCest
RMSEest <- sqrt(var(sin(samples)) / n_real)
RMSEest
```

We see that we've got our Monte Carlo estimate to (near enough) the desired accuracy.
:::

We could phrase out desired tolerance about accuracy using the central limit theorem approximation. Recall that, in the normal distribution, we expect to be within $1.96$ standard deviations of the mean with 95% probability.

So our previous example could interpret this as a $1.96\epsilon$ "margin of error" or a "95% confidence interval" of $`r round(MCest, 5)` \pm (2.0\times 10^{-4})$.

Let's end on a piece of bad news. We noticed that to get an RMSE of $\epsilon$ we need order $1/\epsilon^2$ samples. That's not good. Think of it like this: to *double* or accuracy, we need to *quadruple* the number of samples. Even worse: to get "one more decimal place of accuracy" means dividing $\epsilon$ by ten; but that means multiplying the number of samples by one hundred!

Wouldn't it be nice to have some better ways of increasing the accuracy of a Monte Carlo estimate besides just taking more and more samples? **Next time:** *We begin our study of clever "variance reduction" methods for Monte Carlo estimation.* 