# MCMC error

{{< include ../_header.qmd >}}

## Bias for MCMC

Back in Lectures 3 and 4 we looked at the bias, variance, mean-square error and root-mean-square error for the Monte Carlo estimator
$$ \widehat\theta_n^{\mathrm{MC}} = \frac{1}{n} \sum_{i=1}^n \phi(X_i) $$
of $\theta = \operatorname{\mathbb E}\phi(X)$ where the samples $X_i$ are IID with the same distribution as $X$. We saw that the estimator is unbiased, and that the variance and mean-square error are
$$ \Var\big(\widehat\theta_n^{\mathrm{MC}}\big) = \operatorname{MSE} \big(\widehat\theta_n^{\mathrm{MC}}\big) = \frac{1}{n} \Var\big(\phi(X)\big) . $$

We now want to find these same values where the samples $X_i$ are not IID but are the output of a Markov chain whose stationary distribution is that of $X$. This will be harder. We saw (under certain technical conditions that we will assume hold throughout) that the $X_i$ tend to the distribution of $X$ in the limit as $i \to \infty$. But this is not the same as saying that their distribution is exactly the same as $X$ (let alone are independent). So here we can get as far as
$$ \Exg \widehat\theta_n^{\mathrm{MC}} =  \Exg \left(\frac{1}{n} \sum_{i=1}^n \phi(X_i) \right) = \frac{1}{n} \sum_{i=1}^n \Exg\phi(X_i) $$
(remembering that linearity of expectation does not require independence), but then we're a bit stuck.

To make progress, we will make a simplifying assumption. Suppose we picked the initial state $X_1$ according to the distribution $\pi$. Then, since $\pi$ is a stationary distribution, $X_2$ is distributed according to $\pi$ too. And $X_3$, and $X_4$, and so on. And $\pi$ itself is the distribution for $X$. So, if we started from the stationary distribution -- or "in equilibrium" -- then we have
$$  \Exg \widehat\theta_n^{\mathrm{MC}} =  \Exg \left(\frac{1}{n} \sum_{i=1}^n \phi(X_i) \right) = \frac{1}{n} \sum_{i=1}^n \Exg\phi(X_i) = \frac{1}{n}\,n\Exg\phi(X) = \Exg\phi(X) ,$$
and our estimator is unbiased.

Of course, in real life, it is highly unlikely that we are able to sample the initial state from $\pi$. After all, if we could do that, we could presumably sample all the $X_i$ from $\pi$ independently, as just use the basic Monte Carlo estimator instead. However, if we have used a burn-in period of appropriate length, we hope that by the time we take the first sample "that counts", after the burn-in period, that will be very close to the stationary distribution, and hence we will have 
$$  \Exg \widehat\theta_n^{\mathrm{MC}} \approx \Exg\phi(X) ,$$
and our estimator will be approximately unbiased.

## Variance for MCMC

What about the variance of the MCMC estimator. Unlike the basic IID Monte Carlo case, we can no longer say 
$$  \Var \big( \widehat\theta_n^{\mathrm{MC}}\big) =  \Var \left(\frac{1}{n} \sum_{i=1}^n \phi(X_i) \right) = \frac{1}{n^2} \sum_{i=1}^n \Var\big(\phi(X_i)\big),$$
because the samples from a Markov chain are not independent (although we have limited their dependence structure).

Instead, we have to include the "cross" covariance terms:
$$  \Var \big( \widehat\theta_n^{\mathrm{MC}}\big) =  \Var \left(\frac{1}{n} \sum_{i=1}^n \phi(X_i) \right) = \frac{1}{n^2} \left(\sum_{i=1}^n \Var\big(\phi(X_i)\big) + 2 \sum_{i < j} \Cov\big(\phi(X_i), \phi(X_j)\big) \right) .$$

Again, we grind to a halt as far as exact results are concerned. But we can again invoke our simplifying assumption that $X_1$ was chosen from $\pi$, and that we are in equilibrium. Then the variance terms are all $\Var(\phi(X_i)) = \Var(\phi(X))$, which I shall call $\sigma^2$. What about the covariance terms? Well, if the Markov chain is stationary, then $\Cov(\phi(X_i), \phi(X_j))$ only depends on how many steps apart $i$ and $j$ are. In equilibrium, $\Cov(\phi(X_1), \phi(X_7))$ is the same as $\Cov(\phi(X_2), \phi(X_8))$ or $\Cov(\phi(X_{101}), \phi(X_{107}))$: these all represent the covariance between one state chosen according to $\pi$ and the state $k = 7 - 1 = 6$ steps later.

So here we can write
$$ \Cov\big(\phi(X_i), \phi(X_j)\big) = \gamma(j - i) = \gamma(k) $$
where $k = j - i$ is the number of steps between $i$ and $j$. Students who have studied time series will know that $\gamma(k)$ is called the **autocovariance** at **lag** $k$. (The prefix "auto-" mean "self-", and "lag" means something like a waiting time.)

(The tempting hope that we might have $\gamma(k) = 0$ for $k \geq 2$ is not true. [EXPLAIN])

So now, in equilibrium, we have 
$$  \begin{align}
\Var \big( \widehat\theta_n^{\mathrm{MC}}\big)
&=  \frac{1}{n^2} \left(\sum_{i=1}^n \Var\big(\phi(X_i)\big) + 2 \sum_{i < j} \Cov\big(\phi(X_i), \phi(X_j)\big) \right) \\
&= \frac{1}{n^2} \left(\sum_{i=1}^n \sigma^2 + 2 \sum_{i < j} \gamma(j - i) \right) \\
&=  \frac{1}{n^2} \left(n\sigma^2 + 2 \sum_{i < j} \gamma(j - i) \right)
\end{align} $$

AUTO CORRELATION

SUM TO INFINITY

RESULTS

## Example

COMPARE TO STEP SIZE EXPERIMENTS LAST TIME

If time remains: ADVANTAGES DISADVANTAGES